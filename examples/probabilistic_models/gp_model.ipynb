{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf3265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from lume_model.variables import ScalarVariable, DistributionVariable\n",
    "from lume_model.models.gp_model import GPModel\n",
    "from gpytorch.kernels import RBFKernel\n",
    "from gpytorch.kernels import ScaleKernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95b1b10-5acd-4e26-8b74-2d243e0ce0be",
   "metadata": {},
   "source": [
    "# Multi-output example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53eab389-be6f-48a9-9521-c01a0c17a0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior Mean for each output:\n",
      "tensor([[ 0.2050,  0.8345,  0.4122],\n",
      "        [ 0.6937,  0.7963,  1.0434],\n",
      "        [ 1.0670,  0.1745,  0.3672],\n",
      "        [ 0.8972, -0.4612, -0.7233],\n",
      "        [ 0.3288, -0.9288, -0.3088],\n",
      "        [-0.1707, -0.7832,  0.1967],\n",
      "        [-0.6685, -0.1757,  0.0238],\n",
      "        [-0.9328,  0.1558, -0.1630],\n",
      "        [-0.5566,  0.2297,  0.0035],\n",
      "        [-0.1373,  0.2452,  0.2042]], dtype=torch.float64,\n",
      "       grad_fn=<CloneBackward0>)\n",
      "\n",
      "Posterior Variance for each output:\n",
      "tensor([[1.1023e-01, 1.3304e-01, 9.4012e-02],\n",
      "        [7.6222e-04, 3.0346e-03, 4.2899e-04],\n",
      "        [2.8662e-02, 3.8413e-02, 2.4013e-02],\n",
      "        [1.1967e-02, 1.6607e-02, 1.0005e-02],\n",
      "        [5.1544e-02, 5.3809e-02, 4.5043e-02],\n",
      "        [1.0373e-01, 1.0429e-01, 9.1084e-02],\n",
      "        [2.4203e-01, 2.3610e-01, 2.1332e-01],\n",
      "        [4.6992e-03, 8.8862e-03, 3.6847e-03],\n",
      "        [3.7522e-01, 3.6355e-01, 3.3097e-01],\n",
      "        [5.7309e-01, 5.5293e-01, 5.0575e-01]], dtype=torch.float64,\n",
      "       grad_fn=<CloneBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# Create training data, 1 input, 3 outputs\n",
    "train_x = torch.rand(5, 1)\n",
    "train_y = torch.stack(\n",
    "    (\n",
    "        torch.sin(train_x * (2 * torch.pi)) + 0.1 * torch.randn(1),\n",
    "        torch.cos(train_x * (2 * torch.pi)) + 0.1 * torch.randn(1),\n",
    "        torch.sin(2 * train_x * (2 * torch.pi)) + 0.1 * torch.randn(1),\n",
    "    ),\n",
    "    dim=-1,\n",
    ").squeeze(1)\n",
    "\n",
    "\n",
    "# Initialize the GP model\n",
    "rbf_kernel = ScaleKernel(RBFKernel())\n",
    "\n",
    "model = SingleTaskGP(\n",
    "    train_x.to(dtype=torch.double),\n",
    "    train_y.to(dtype=torch.double),\n",
    "    covar_module=rbf_kernel,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "fit_gpytorch_mll(mll)\n",
    "\n",
    "# Derive posterior mean and variance\n",
    "model.eval()\n",
    "test_x = torch.linspace(0, 1, 10).reshape(-1, 1).to(dtype=torch.double)\n",
    "posterior = model.posterior(test_x)\n",
    "\n",
    "# Derive the posterior mean and variance for each output\n",
    "mean = posterior.mean\n",
    "variance = posterior.variance\n",
    "print(\"Posterior Mean for each output:\")\n",
    "print(mean)\n",
    "print(\"\\nPosterior Variance for each output:\")\n",
    "print(variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b316363-a154-4ba8-b96b-30a22e400a35",
   "metadata": {},
   "source": [
    "## LUME-Model import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "746f7554-d317-400c-9e9b-47cb38422e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input variables\n",
    "input_variables = [ScalarVariable(name=\"x\")]\n",
    "\n",
    "# Define output variables\n",
    "# Currently the \"distribution_type\" field doesn't do anything\n",
    "output_variables = [\n",
    "    DistributionVariable(name=\"output1\", distribution_type=\"MultiVariateNormal\"),\n",
    "    DistributionVariable(name=\"output2\", distribution_type=\"MultiVariateNormal\"),\n",
    "    DistributionVariable(name=\"output3\", distribution_type=\"MultiVariateNormal\"),\n",
    "]\n",
    "\n",
    "# Create lume_model instance\n",
    "gp_lume_model = GPModel(\n",
    "    model=model, input_variables=input_variables, output_variables=output_variables\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ebbfdf-6bc4-4eae-a225-cce92a0e80e7",
   "metadata": {},
   "source": [
    "### Evaluate model and run methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b23c0a4-bf07-4351-b6e7-0762346f6e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {\"x\": test_x.squeeze(1).to(dtype=torch.double)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "567cc4fb-aa01-40d6-be27-4839eaf23ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889,\n",
       "         1.0000], dtype=torch.float64)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a20e922c-22e3-445d-913d-b735ab7c62fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate function returns a dictionary mapping each output to a torch.distributions.Distribution\n",
    "output_dict = gp_lume_model.evaluate(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2028eda3-7e67-474e-9d71-9d286d3f0749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output1': MultivariateNormal(loc: torch.Size([10]), covariance_matrix: torch.Size([10, 10])),\n",
       " 'output2': MultivariateNormal(loc: torch.Size([10]), covariance_matrix: torch.Size([10, 10])),\n",
       " 'output3': MultivariateNormal(loc: torch.Size([10]), covariance_matrix: torch.Size([10, 10]))}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "410be85e-8342-4441-b739-3f3f342d1810",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prob = output_dict[\"output1\"].sample(torch.Size([2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77268fda-342b-4319-bc50-2504e9b65817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior mean: tensor([ 0.2050,  0.6937,  1.0670,  0.8972,  0.3288, -0.1707, -0.6685, -0.9328,\n",
      "        -0.5566, -0.1373], dtype=torch.float64, grad_fn=<ExpandBackward0>)\n",
      "Posterior Variance  tensor([0.1102, 0.0008, 0.0287, 0.0120, 0.0515, 0.1037, 0.2420, 0.0047, 0.3752,\n",
      "        0.5731], dtype=torch.float64, grad_fn=<ExpandBackward0>)\n",
      "Log Likelihood tensor([4.5356, 4.6654], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "Rsample  tensor([[ 1.0552e-01,  7.1237e-01,  1.2059e+00,  8.3028e-01,  1.0869e-01,\n",
      "          7.1085e-03, -9.0223e-01, -9.2138e-01, -7.6623e-01, -6.2605e-01],\n",
      "        [ 3.7840e-04,  6.9813e-01,  9.1871e-01,  1.0180e+00,  5.5303e-01,\n",
      "         -7.8040e-01, -1.2117e+00, -9.9632e-01, -1.2616e+00, -7.7939e-01],\n",
      "        [-4.3100e-01,  6.9217e-01,  9.9770e-01,  8.6105e-01,  3.0568e-01,\n",
      "         -2.0983e-01, -9.1296e-01, -8.8088e-01,  6.1089e-02,  2.8746e-01]],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Posterior mean:\", output_dict[\"output1\"].mean)\n",
    "print(\"Posterior Variance \", output_dict[\"output1\"].variance)\n",
    "print(\"Log Likelihood\", output_dict[\"output1\"].log_prob(test_prob))\n",
    "print(\"Rsample \", output_dict[\"output1\"].rsample(torch.Size([3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5326ad-fd2a-4432-bae2-19c078c86d8c",
   "metadata": {},
   "source": [
    "### Outputs with original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9883480-f8fd-4899-8417-a8e041da0204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior mean: tensor([ 0.2050,  0.6937,  1.0670,  0.8972,  0.3288, -0.1707, -0.6685, -0.9328,\n",
      "        -0.5566, -0.1373], dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "Posterior Variance  tensor([0.1102, 0.0008, 0.0287, 0.0120, 0.0515, 0.1037, 0.2420, 0.0047, 0.3752,\n",
      "        0.5731], dtype=torch.float64, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Posterior mean:\", posterior.mean[:, 0])\n",
    "print(\"Posterior Variance \", posterior.variance[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e909f9-5d88-49a3-a8e6-777774a57b4b",
   "metadata": {},
   "source": [
    "# A 3D Rosenbrock example for GPModel class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13423e73-2e5b-419d-be48-c979472a281c",
   "metadata": {},
   "source": [
    "## Create and train a GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e1caf84-00be-414d-a9b6-9d4f846290e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 3D Rosenbrock function\n",
    "def rosenbrock(X):\n",
    "    x1, x2, x3 = X[..., 0], X[..., 1], X[..., 2]\n",
    "    return (\n",
    "        (1 - x1) ** 2\n",
    "        + 100 * (x2 - x1**2) ** 2\n",
    "        + (1 - x2) ** 2\n",
    "        + 100 * (x3 - x2**2) ** 2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9ed72c5-3256-4b17-9713-54d2eb46dac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior mean:  tensor([[ 589.6488],\n",
      "        [ 414.3726],\n",
      "        [ 379.7021],\n",
      "        [ -63.6949],\n",
      "        [1231.5723],\n",
      "        [ -96.9024],\n",
      "        [1341.5255],\n",
      "        [-258.7856],\n",
      "        [ 980.1755],\n",
      "        [ 612.8108]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Posterior variance:  tensor([[72240.6283],\n",
      "        [27952.7022],\n",
      "        [ 3173.3891],\n",
      "        [17167.4324],\n",
      "        [11905.8578],\n",
      "        [10077.6879],\n",
      "        [ 4033.4934],\n",
      "        [ 6140.0747],\n",
      "        [17327.2274],\n",
      "        [58078.6172]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Generate training data\n",
    "train_x = torch.rand(20, 3) * 4 - 2  # 20 points in 3D space, scaled to [-2, 2]\n",
    "train_y = rosenbrock(train_x).unsqueeze(-1)  # Compute the Rosenbrock function values\n",
    "\n",
    "# Define the GP model\n",
    "gp_model = SingleTaskGP(train_x.to(dtype=torch.double), train_y.to(dtype=torch.double))\n",
    "\n",
    "# Fit the model\n",
    "mll = ExactMarginalLogLikelihood(gp_model.likelihood, gp_model)\n",
    "fit_gpytorch_mll(mll)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_x = torch.rand(10, 3) * 4 - 2  # 10 new points in 3D space\n",
    "gp_model.eval()\n",
    "posterior = gp_model.posterior(test_x)\n",
    "\n",
    "# Get the mean and variance of the posterior\n",
    "mean = posterior.mean\n",
    "variance = posterior.variance\n",
    "\n",
    "print(\"Posterior mean: \", mean)\n",
    "print(\"Posterior variance: \", variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f42d852-dbef-4ec8-814a-fa3f94b8f24b",
   "metadata": {},
   "source": [
    "## LUME-Model import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d256cedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input variables\n",
    "input_variables = [\n",
    "    ScalarVariable(name=\"x1\"),\n",
    "    ScalarVariable(name=\"x2\"),\n",
    "    ScalarVariable(name=\"x3\"),\n",
    "]\n",
    "\n",
    "# Define output variables\n",
    "# Currently the \"distribution_type\" field doesn't do anything\n",
    "output_variables = [\n",
    "    DistributionVariable(name=\"output1\", distribution_type=\"MultiVariateNormal\")\n",
    "]\n",
    "\n",
    "# Create lume_model instance\n",
    "gp_lume_model = GPModel(\n",
    "    model=gp_model, input_variables=input_variables, output_variables=output_variables\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8144a2e-7221-4c4f-8b40-d07d21e67e31",
   "metadata": {},
   "source": [
    "#### Evaluate model and run methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8e61307-8ff8-45ea-8ea1-d2a846e3beaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x = torch.rand(3, 3) * 4 - 2  # 3 new points in 3D space\n",
    "input_dict = {\n",
    "    \"x1\": input_x[:, 0].to(dtype=torch.double),\n",
    "    \"x2\": input_x[:, 1].to(dtype=torch.double),\n",
    "    \"x3\": input_x[:, 2].to(dtype=torch.double),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb69c88b-a94d-4c0b-bee8-2ae0b40a3577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate function returns a dictionary mapping each output to a torch.distributions.Distribution\n",
    "lume_dist = gp_lume_model.evaluate(input_dict)[\"output1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "424760a2-2626-4c60-a7db-9baaf1b60084",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_test = torch.rand(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9c4f8d8-da8e-44d2-b18c-53fb6f75897a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior mean: tensor([ 612.0247, 1552.4470, 1511.9490], dtype=torch.float64,\n",
      "       grad_fn=<ExpandBackward0>)\n",
      "Posterior Variance  tensor([ 3687.1288, 92138.0799, 12148.2341], dtype=torch.float64,\n",
      "       grad_fn=<ExpandBackward0>)\n",
      "Log Likelihood tensor([-161.8829], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "Rsample  tensor([[ 627.1446, 1884.3308, 1591.7666],\n",
      "        [ 616.3797, 1960.4848, 1527.1977],\n",
      "        [ 643.1253, 1825.0287, 1611.2168]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Posterior mean:\", lume_dist.mean)\n",
    "print(\"Posterior Variance \", lume_dist.variance)\n",
    "print(\"Log Likelihood\", lume_dist.log_prob(rand_test))\n",
    "print(\"Rsample \", lume_dist.rsample(torch.Size([3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b8ab31-78e7-4d2c-816a-b8c8373f427a",
   "metadata": {},
   "source": [
    "### Outputs with original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd60e0f6-9e0e-47e0-8fa5-82b97778375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = gp_model.posterior(input_x)\n",
    "botorch_dist = posterior.distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d0254a6-6059-420c-9184-ca8bc4b464d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior mean: tensor([ 612.0247, 1552.4470, 1511.9490], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Posterior Variance  tensor([ 3687.1288, 92138.0799, 12148.2341], dtype=torch.float64,\n",
      "       grad_fn=<ExpandBackward0>)\n",
      "Log Likelihood tensor([-161.8829], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "Rsample  tensor([[ 567.7197, 1495.8050, 1409.5655],\n",
      "        [ 470.0016, 1833.1275, 1506.4477],\n",
      "        [ 628.6214, 1976.9459, 1510.3016]], dtype=torch.float64,\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Posterior mean:\", botorch_dist.mean)\n",
    "print(\"Posterior Variance \", botorch_dist.variance)\n",
    "print(\"Log Likelihood\", botorch_dist.log_prob(rand_test))\n",
    "print(\"Rsample \", botorch_dist.rsample(torch.Size([3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f18e906-fdcb-4431-8a12-2e9054bb259f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86101be0-70a7-4493-be42-4fab75096e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
