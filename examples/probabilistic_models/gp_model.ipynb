{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf3265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from lume_model.variables import ScalarVariable, DistributionVariable\n",
    "from lume_model.models.gp_model import GPModel\n",
    "from gpytorch.kernels import RBFKernel\n",
    "from gpytorch.kernels import ScaleKernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95b1b10-5acd-4e26-8b74-2d243e0ce0be",
   "metadata": {},
   "source": [
    "# Multi-output example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53eab389-be6f-48a9-9521-c01a0c17a0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior Mean for each output:\n",
      "tensor([[ 0.2397,  0.7271,  0.4191],\n",
      "        [ 0.6916,  0.7995,  1.0390],\n",
      "        [ 1.0555,  0.1417,  0.3111],\n",
      "        [ 0.8914, -0.4485, -0.6847],\n",
      "        [ 0.3121, -0.9120, -0.2559],\n",
      "        [-0.1309, -0.7975,  0.1390],\n",
      "        [-0.6172, -0.1708, -0.0208],\n",
      "        [-0.9243,  0.1479, -0.1613],\n",
      "        [-0.4698,  0.0957, -0.0618],\n",
      "        [-0.0174,  0.0081,  0.0473]], dtype=torch.float64,\n",
      "       grad_fn=<CloneBackward0>)\n",
      "\n",
      "Posterior Variance for each output:\n",
      "tensor([[0.1171, 0.1131, 0.1045],\n",
      "        [0.0022, 0.0021, 0.0021],\n",
      "        [0.0380, 0.0367, 0.0341],\n",
      "        [0.0156, 0.0150, 0.0140],\n",
      "        [0.0529, 0.0511, 0.0469],\n",
      "        [0.0965, 0.0931, 0.0854],\n",
      "        [0.2123, 0.2048, 0.1875],\n",
      "        [0.0069, 0.0067, 0.0063],\n",
      "        [0.3026, 0.2919, 0.2671],\n",
      "        [0.4321, 0.4169, 0.3814]], dtype=torch.float64,\n",
      "       grad_fn=<CloneBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# Create training data, 1 input, 3 outputs\n",
    "train_x = torch.rand(5, 1)\n",
    "train_y = torch.stack(\n",
    "    (\n",
    "        torch.sin(train_x * (2 * torch.pi)) + 0.1 * torch.randn(1),\n",
    "        torch.cos(train_x * (2 * torch.pi)) + 0.1 * torch.randn(1),\n",
    "        torch.sin(2 * train_x * (2 * torch.pi)) + 0.1 * torch.randn(1),\n",
    "    ),\n",
    "    dim=-1,\n",
    ").squeeze(1)\n",
    "\n",
    "\n",
    "# Initialize the GP model\n",
    "rbf_kernel = ScaleKernel(RBFKernel())\n",
    "\n",
    "model = SingleTaskGP(\n",
    "    train_x.to(dtype=torch.double),\n",
    "    train_y.to(dtype=torch.double),\n",
    "    covar_module=rbf_kernel,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "fit_gpytorch_mll(mll)\n",
    "\n",
    "# Derive posterior mean and variance\n",
    "model.eval()\n",
    "test_x = torch.linspace(0, 1, 10).reshape(-1, 1).to(dtype=torch.double)\n",
    "posterior = model.posterior(test_x)\n",
    "\n",
    "# Derive the posterior mean and variance for each output\n",
    "mean = posterior.mean\n",
    "variance = posterior.variance\n",
    "print(\"Posterior Mean for each output:\")\n",
    "print(mean)\n",
    "print(\"\\nPosterior Variance for each output:\")\n",
    "print(variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b316363-a154-4ba8-b96b-30a22e400a35",
   "metadata": {},
   "source": [
    "## LUME-Model import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "746f7554-d317-400c-9e9b-47cb38422e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input variables\n",
    "input_variables = [ScalarVariable(name=\"x\")]\n",
    "\n",
    "# Define output variables\n",
    "output_variables = [\n",
    "    DistributionVariable(name=\"output1\"),\n",
    "    DistributionVariable(name=\"output2\"),\n",
    "    DistributionVariable(name=\"output3\"),\n",
    "]\n",
    "\n",
    "# Create lume_model instance\n",
    "gp_lume_model = GPModel(\n",
    "    model=model, input_variables=input_variables, output_variables=output_variables\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ebbfdf-6bc4-4eae-a225-cce92a0e80e7",
   "metadata": {},
   "source": [
    "### Evaluate model and run methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b23c0a4-bf07-4351-b6e7-0762346f6e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {\"x\": test_x.squeeze(1).to(dtype=torch.double)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "567cc4fb-aa01-40d6-be27-4839eaf23ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889,\n",
       "         1.0000], dtype=torch.float64)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a20e922c-22e3-445d-913d-b735ab7c62fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate function returns a dictionary mapping each output to a torch.distributions.Distribution\n",
    "output_dict = gp_lume_model.evaluate(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2028eda3-7e67-474e-9d71-9d286d3f0749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output1': MultivariateNormal(loc: torch.Size([10]), covariance_matrix: torch.Size([10, 10])),\n",
       " 'output2': MultivariateNormal(loc: torch.Size([10]), covariance_matrix: torch.Size([10, 10])),\n",
       " 'output3': MultivariateNormal(loc: torch.Size([10]), covariance_matrix: torch.Size([10, 10]))}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "410be85e-8342-4441-b739-3f3f342d1810",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prob = output_dict[\"output1\"].sample(torch.Size([2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77268fda-342b-4319-bc50-2504e9b65817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior mean: tensor([ 0.2397,  0.6916,  1.0555,  0.8914,  0.3121, -0.1309, -0.6172, -0.9243,\n",
      "        -0.4698, -0.0174], dtype=torch.float64, grad_fn=<ExpandBackward0>)\n",
      "Posterior Variance  tensor([0.1171, 0.0022, 0.0380, 0.0156, 0.0529, 0.0965, 0.2123, 0.0069, 0.3026,\n",
      "        0.4321], dtype=torch.float64, grad_fn=<ExpandBackward0>)\n",
      "Log Likelihood tensor([2.8670, 1.3911], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "Rsample  tensor([[ 0.1371,  0.7029,  0.7924,  0.9986,  0.3675, -0.5925, -1.3643, -0.9383,\n",
      "         -0.1128,  0.4696],\n",
      "        [ 0.4477,  0.6424,  0.8958,  0.8927,  0.4303,  0.1575, -0.1585, -0.9204,\n",
      "         -0.4836,  0.2818],\n",
      "        [ 0.6743,  0.6468,  0.9740,  0.9098,  0.3655, -0.4459, -1.5865, -0.8818,\n",
      "         -0.3347, -0.3025]], dtype=torch.float64, grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Posterior mean:\", output_dict[\"output1\"].mean)\n",
    "print(\"Posterior Variance \", output_dict[\"output1\"].variance)\n",
    "print(\"Log Likelihood\", output_dict[\"output1\"].log_prob(test_prob))\n",
    "print(\"Rsample \", output_dict[\"output1\"].rsample(torch.Size([3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5326ad-fd2a-4432-bae2-19c078c86d8c",
   "metadata": {},
   "source": [
    "### Outputs with original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9883480-f8fd-4899-8417-a8e041da0204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior mean: tensor([ 0.2397,  0.6916,  1.0555,  0.8914,  0.3121, -0.1309, -0.6172, -0.9243,\n",
      "        -0.4698, -0.0174], dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "Posterior Variance  tensor([0.1171, 0.0022, 0.0380, 0.0156, 0.0529, 0.0965, 0.2123, 0.0069, 0.3026,\n",
      "        0.4321], dtype=torch.float64, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Posterior mean:\", posterior.mean[:, 0])\n",
    "print(\"Posterior Variance \", posterior.variance[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e909f9-5d88-49a3-a8e6-777774a57b4b",
   "metadata": {},
   "source": [
    "# A 3D Rosenbrock example for GPModel class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13423e73-2e5b-419d-be48-c979472a281c",
   "metadata": {},
   "source": [
    "## Create and train a GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e1caf84-00be-414d-a9b6-9d4f846290e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 3D Rosenbrock function\n",
    "def rosenbrock(X):\n",
    "    x1, x2, x3 = X[..., 0], X[..., 1], X[..., 2]\n",
    "    return (\n",
    "        (1 - x1) ** 2\n",
    "        + 100 * (x2 - x1**2) ** 2\n",
    "        + (1 - x2) ** 2\n",
    "        + 100 * (x3 - x2**2) ** 2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9ed72c5-3256-4b17-9713-54d2eb46dac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior mean:  tensor([[ 606.3839],\n",
      "        [ 685.3384],\n",
      "        [1196.5879],\n",
      "        [1049.7149],\n",
      "        [ 258.3421],\n",
      "        [1224.6845],\n",
      "        [ 926.0569],\n",
      "        [ 801.6735],\n",
      "        [ 334.0830],\n",
      "        [ 529.1804]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n",
      "Posterior variance:  tensor([[ 28350.0389],\n",
      "        [246126.2279],\n",
      "        [129956.1835],\n",
      "        [ 73671.8765],\n",
      "        [ 27067.5129],\n",
      "        [154205.9639],\n",
      "        [180241.9565],\n",
      "        [206996.4155],\n",
      "        [ 44488.5639],\n",
      "        [ 73535.2854]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/smiskov/miniconda3/envs/lume-latest/lib/python3.10/site-packages/botorch/models/utils/assorted.py:264: InputDataWarning: Data (input features) is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  check_min_max_scaling(\n"
     ]
    }
   ],
   "source": [
    "# Generate training data\n",
    "train_x = torch.rand(20, 3) * 4 - 2  # 20 points in 3D space, scaled to [-2, 2]\n",
    "train_y = rosenbrock(train_x).unsqueeze(-1)  # Compute the Rosenbrock function values\n",
    "\n",
    "# Define the GP model\n",
    "gp_model = SingleTaskGP(train_x.to(dtype=torch.double), train_y.to(dtype=torch.double))\n",
    "\n",
    "# Fit the model\n",
    "mll = ExactMarginalLogLikelihood(gp_model.likelihood, gp_model)\n",
    "fit_gpytorch_mll(mll)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_x = torch.rand(10, 3) * 4 - 2  # 10 new points in 3D space\n",
    "gp_model.eval()\n",
    "posterior = gp_model.posterior(test_x)\n",
    "\n",
    "# Get the mean and variance of the posterior\n",
    "mean = posterior.mean\n",
    "variance = posterior.variance\n",
    "\n",
    "print(\"Posterior mean: \", mean)\n",
    "print(\"Posterior variance: \", variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f42d852-dbef-4ec8-814a-fa3f94b8f24b",
   "metadata": {},
   "source": [
    "## LUME-Model import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d256cedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input variables\n",
    "input_variables = [\n",
    "    ScalarVariable(name=\"x1\"),\n",
    "    ScalarVariable(name=\"x2\"),\n",
    "    ScalarVariable(name=\"x3\"),\n",
    "]\n",
    "\n",
    "# Define output variables\n",
    "output_variables = [DistributionVariable(name=\"output1\")]\n",
    "\n",
    "# Create lume_model instance\n",
    "gp_lume_model = GPModel(\n",
    "    model=gp_model, input_variables=input_variables, output_variables=output_variables\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8144a2e-7221-4c4f-8b40-d07d21e67e31",
   "metadata": {},
   "source": [
    "#### Evaluate model and run methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8e61307-8ff8-45ea-8ea1-d2a846e3beaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x = torch.rand(3, 3) * 4 - 2  # 3 new points in 3D space\n",
    "input_dict = {\n",
    "    \"x1\": input_x[:, 0].to(dtype=torch.double),\n",
    "    \"x2\": input_x[:, 1].to(dtype=torch.double),\n",
    "    \"x3\": input_x[:, 2].to(dtype=torch.double),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb69c88b-a94d-4c0b-bee8-2ae0b40a3577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate function returns a dictionary mapping each output to a torch.distributions.Distribution\n",
    "lume_dist = gp_lume_model.evaluate(input_dict)[\"output1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "424760a2-2626-4c60-a7db-9baaf1b60084",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_test = torch.rand(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9c4f8d8-da8e-44d2-b18c-53fb6f75897a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior mean: tensor([ 144.1534,  750.6190, 1551.5102], dtype=torch.float64,\n",
      "       grad_fn=<ExpandBackward0>)\n",
      "Posterior Variance  tensor([107860.9063, 105648.6779,  77374.0159], dtype=torch.float64,\n",
      "       grad_fn=<ExpandBackward0>)\n",
      "Log Likelihood tensor([-35.7136], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "Rsample  tensor([[ 225.9312,  858.3771, 2018.9276],\n",
      "        [ 315.6748, 1014.5847, 1271.6913],\n",
      "        [ 368.0957, 1014.4358, 2090.0455]], dtype=torch.float64,\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Posterior mean:\", lume_dist.mean)\n",
    "print(\"Posterior Variance \", lume_dist.variance)\n",
    "print(\"Log Likelihood\", lume_dist.log_prob(rand_test))\n",
    "print(\"Rsample \", lume_dist.rsample(torch.Size([3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b8ab31-78e7-4d2c-816a-b8c8373f427a",
   "metadata": {},
   "source": [
    "### Outputs with original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd60e0f6-9e0e-47e0-8fa5-82b97778375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = gp_model.posterior(input_x)\n",
    "botorch_dist = posterior.distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d0254a6-6059-420c-9184-ca8bc4b464d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior mean: tensor([ 144.1534,  750.6190, 1551.5102], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Posterior Variance  tensor([107860.9063, 105648.6779,  77374.0159], dtype=torch.float64,\n",
      "       grad_fn=<ExpandBackward0>)\n",
      "Log Likelihood tensor([-35.7136], dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "Rsample  tensor([[  76.0090,  322.3840, 1341.8768],\n",
      "        [ 129.2442,  821.3236, 1278.1483],\n",
      "        [-149.8472,  711.9353, 1303.4597]], dtype=torch.float64,\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Posterior mean:\", botorch_dist.mean)\n",
    "print(\"Posterior Variance \", botorch_dist.variance)\n",
    "print(\"Log Likelihood\", botorch_dist.log_prob(rand_test))\n",
    "print(\"Rsample \", botorch_dist.rsample(torch.Size([3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f18e906-fdcb-4431-8a12-2e9054bb259f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86101be0-70a7-4493-be42-4fab75096e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
